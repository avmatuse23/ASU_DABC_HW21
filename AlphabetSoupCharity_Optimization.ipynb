{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34299 entries, 0 to 34298\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   EIN                     34299 non-null  int64 \n",
      " 1   NAME                    34299 non-null  object\n",
      " 2   APPLICATION_TYPE        34299 non-null  object\n",
      " 3   AFFILIATION             34299 non-null  object\n",
      " 4   CLASSIFICATION          34299 non-null  object\n",
      " 5   USE_CASE                34299 non-null  object\n",
      " 6   ORGANIZATION            34299 non-null  object\n",
      " 7   STATUS                  34299 non-null  int64 \n",
      " 8   INCOME_AMT              34299 non-null  object\n",
      " 9   SPECIAL_CONSIDERATIONS  34299 non-null  object\n",
      " 10  ASK_AMT                 34299 non-null  int64 \n",
      " 11  IS_SUCCESSFUL           34299 non-null  int64 \n",
      "dtypes: int64(4), object(8)\n",
      "memory usage: 3.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "display(application_df.info())\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34299, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>Association</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Trust</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Trust</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION  ORGANIZATION  \\\n",
       "0              T10       Independent          C1000   Association   \n",
       "1               T3       Independent          C2000  Co-operative   \n",
       "2               T5  CompanySponsored          C3000   Association   \n",
       "3               T3  CompanySponsored          C2000         Trust   \n",
       "4               T3       Independent          C1000         Trust   \n",
       "\n",
       "      INCOME_AMT  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0     5000              1  \n",
       "1         1-9999   108590              1  \n",
       "2              0     5000              0  \n",
       "3    10000-24999     6692              1  \n",
       "4  100000-499999   142590              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'\n",
    "application_df.drop(['EIN', 'NAME', 'USE_CASE', 'STATUS', 'SPECIAL_CONSIDERATIONS'], axis='columns', inplace=True)\n",
    "display(application_df.shape)\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Droped USE_CASE, STATUS, SPECIAL_CONSIDERATIONS based on Decision Tree for feature importances evaluation. \n",
    "See **Features_Importances_all_data.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE      17\n",
       "AFFILIATION            6\n",
       "CLASSIFICATION        71\n",
       "ORGANIZATION           4\n",
       "INCOME_AMT             9\n",
       "ASK_AMT             8747\n",
       "IS_SUCCESSFUL          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = ['T9', 'T13', 'T12', 'T2', 'T25', 'T14', 'T29', 'T15', 'T17']\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C4120        1\n",
       "C8210        1\n",
       "C2561        1\n",
       "C4500        1\n",
       "C2150        1\n",
       "Name: count, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1000</td>\n",
       "      <td>17326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C2000</td>\n",
       "      <td>6074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C3000</td>\n",
       "      <td>1918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C1200</td>\n",
       "      <td>4837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C2700</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLASSIFICATION  COUNT\n",
       "0           C1000  17326\n",
       "1           C2000   6074\n",
       "2           C3000   1918\n",
       "5           C1200   4837\n",
       "13          C2700    104"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(66, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C2700</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C7000</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>C7200</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>C1700</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>C4000</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLASSIFICATION  COUNT\n",
       "13          C2700    104\n",
       "22          C7000    777\n",
       "44          C7200     32\n",
       "48          C1700    287\n",
       "73          C4000    194"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts \n",
    "classification = application_df.copy()\n",
    "classification[\"COUNT\"] = classification.groupby(['CLASSIFICATION'])['CLASSIFICATION'].transform(lambda x: x.count())\n",
    "classification_all = classification[['CLASSIFICATION', 'COUNT']]\n",
    "classification_all = classification_all.drop_duplicates(subset=['CLASSIFICATION'], keep='first')\n",
    "classification_g1 = classification_all.loc[(classification_all[\"COUNT\"] > 1)]\n",
    "classification_l1883 = classification_all.loc[(classification_all[\"COUNT\"] < 1883)]\n",
    "display(classification_g1.shape)\n",
    "display(classification_g1.head())\n",
    "display(classification_l1883.shape)\n",
    "display(classification_l1883.head())\n",
    "classifications_to_replace = classification_l1883['CLASSIFICATION'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Create binning for INCOME_AMT based on Decision Tree for feature importances evaluation. <br>\n",
    "See **Features_Importances_all_data.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCOME_AMT\n",
       "0                24388\n",
       "25000-99999       3747\n",
       "100000-499999     3374\n",
       "1M-5M              955\n",
       "1-9999             728\n",
       "10000-24999        543\n",
       "10M-50M            240\n",
       "5M-10M             185\n",
       "50M+               139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at INCOME_AMT value counts for binning\n",
    "application_df['INCOME_AMT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCOME_AMT\n",
       "0                24388\n",
       "25000-99999       3747\n",
       "100000-499999     3374\n",
       " >= 1M            1519\n",
       "< 10k             1271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "income_atm_low_to_replace = ['1-9999', '10000-24999']\n",
    "income_atm_high_to_replace = ['1M-5M', '10M-50M', '5M-10M', '50M+']\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in income_atm_low_to_replace:\n",
    "    application_df['INCOME_AMT'] = application_df['INCOME_AMT'].replace(app,\"< 10k\")\n",
    "for app in income_atm_high_to_replace:\n",
    "    application_df['INCOME_AMT'] = application_df['INCOME_AMT'].replace(app,\" >= 1M\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['INCOME_AMT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION', 'ORGANIZATION',\n",
       "       'INCOME_AMT', 'ASK_AMT', 'IS_SUCCESSFUL'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34299 entries, 0 to 34298\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   APPLICATION_TYPE  34299 non-null  object\n",
      " 1   AFFILIATION       34299 non-null  object\n",
      " 2   CLASSIFICATION    34299 non-null  object\n",
      " 3   ORGANIZATION      34299 non-null  object\n",
      " 4   INCOME_AMT        34299 non-null  object\n",
      " 5   ASK_AMT           34299 non-null  int64 \n",
      " 6   IS_SUCCESSFUL     34299 non-null  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "display(application_df.columns)\n",
    "application_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "#  YOUR CODE GOES HERE\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>CLASSIFICATION_Other</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_ &gt;= 1M</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_&lt; 10k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
       "0     5000              1                   False                  True   \n",
       "1   108590              1                   False                 False   \n",
       "2     5000              0                   False                 False   \n",
       "3     6692              1                   False                 False   \n",
       "4   142590              1                   False                 False   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                 False                False                False   \n",
       "1                 False                 True                False   \n",
       "2                 False                False                False   \n",
       "3                 False                 True                False   \n",
       "4                 False                 True                False   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                False                False                False  ...   \n",
       "1                False                False                False  ...   \n",
       "2                 True                False                False  ...   \n",
       "3                False                False                False  ...   \n",
       "4                False                False                False  ...   \n",
       "\n",
       "   CLASSIFICATION_Other  ORGANIZATION_Association  ORGANIZATION_Co-operative  \\\n",
       "0                 False                      True                      False   \n",
       "1                 False                     False                       True   \n",
       "2                 False                      True                      False   \n",
       "3                 False                     False                      False   \n",
       "4                 False                     False                      False   \n",
       "\n",
       "   ORGANIZATION_Corporation  ORGANIZATION_Trust  INCOME_AMT_ >= 1M  \\\n",
       "0                     False               False              False   \n",
       "1                     False               False              False   \n",
       "2                     False               False              False   \n",
       "3                     False                True              False   \n",
       "4                     False                True              False   \n",
       "\n",
       "   INCOME_AMT_0  INCOME_AMT_100000-499999  INCOME_AMT_25000-99999  \\\n",
       "0          True                     False                   False   \n",
       "1         False                     False                   False   \n",
       "2          True                     False                   False   \n",
       "3         False                     False                   False   \n",
       "4         False                      True                   False   \n",
       "\n",
       "   INCOME_AMT_< 10k  \n",
       "0             False  \n",
       "1              True  \n",
       "2             False  \n",
       "3              True  \n",
       "4             False  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "df_encoded = pd.get_dummies(application_df, columns=['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION',\n",
    "       'ORGANIZATION', 'INCOME_AMT'])\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ASK_AMT', 'IS_SUCCESSFUL', 'APPLICATION_TYPE_Other',\n",
       "       'APPLICATION_TYPE_T10', 'APPLICATION_TYPE_T19', 'APPLICATION_TYPE_T3',\n",
       "       'APPLICATION_TYPE_T4', 'APPLICATION_TYPE_T5', 'APPLICATION_TYPE_T6',\n",
       "       'APPLICATION_TYPE_T7', 'APPLICATION_TYPE_T8',\n",
       "       'AFFILIATION_CompanySponsored', 'AFFILIATION_Family/Parent',\n",
       "       'AFFILIATION_Independent', 'AFFILIATION_National', 'AFFILIATION_Other',\n",
       "       'AFFILIATION_Regional', 'CLASSIFICATION_C1000', 'CLASSIFICATION_C1200',\n",
       "       'CLASSIFICATION_C2000', 'CLASSIFICATION_C2100', 'CLASSIFICATION_C3000',\n",
       "       'CLASSIFICATION_Other', 'ORGANIZATION_Association',\n",
       "       'ORGANIZATION_Co-operative', 'ORGANIZATION_Corporation',\n",
       "       'ORGANIZATION_Trust', 'INCOME_AMT_ >= 1M', 'INCOME_AMT_0',\n",
       "       'INCOME_AMT_100000-499999', 'INCOME_AMT_25000-99999',\n",
       "       'INCOME_AMT_< 10k'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ASK_AMT', 'AFFILIATION_CompanySponsored', 'APPLICATION_TYPE_T5',\n",
       "       'APPLICATION_TYPE_T10', 'ORGANIZATION_Association',\n",
       "       'APPLICATION_TYPE_T6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select top 6 clms for nn model\n",
    "df_encoded_6_clmX = df_encoded[['ASK_AMT', 'AFFILIATION_CompanySponsored', 'APPLICATION_TYPE_T5', 'APPLICATION_TYPE_T10', 'ORGANIZATION_Association', 'APPLICATION_TYPE_T6']]\n",
    "df_encoded_6_clmX.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Keep top 6 most imortant columns based on Decision Tree for feature importances evaluation. This helps to reduce noise in the nn model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_encoded[\"IS_SUCCESSFUL\"].values\n",
    "y = y.reshape(-1, 1)\n",
    "X = df_encoded_6_clmX\n",
    "#X.drop([\"IS_SUCCESSFUL\"], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree for feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Creating the decision tree classifier instance\n",
    "model = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Making predictions using the testing data\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dtree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6049642094574723, 'ASK_AMT'),\n",
       " (0.25445042344588037, 'AFFILIATION_CompanySponsored'),\n",
       " (0.05236001850653976, 'APPLICATION_TYPE_T5'),\n",
       " (0.038854630999963224, 'APPLICATION_TYPE_T10'),\n",
       " (0.029053178104007083, 'APPLICATION_TYPE_T6'),\n",
       " (0.02031753948613737, 'ORGANIZATION_Association')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = dtree.feature_importances_\n",
    "sorted(zip(dtree.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Features Importances'}, ylabel='1'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances_df = pd.DataFrame(sorted(zip(dtree.feature_importances_, X.columns), reverse=True))\n",
    "importances_df.set_index(importances_df[1], inplace=True)\n",
    "importances_df.drop(columns=1, inplace=True)\n",
    "importances_df.rename(columns={0: 'Feature Importances'}, inplace=True)\n",
    "importances_sorted = importances_df.sort_values(by='Feature Importances')\n",
    "importances_sorted.plot(kind='barh', color='orange', title= 'Features Importances', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe\n",
    "importances_sorted.to_csv('Features_Importances_droped_clms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tune up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','tanh'])\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=30,\n",
    "        step=5), activation=activation, input_dim= len(X_train.axes[1])))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=30,\n",
    "            step=5),\n",
    "            activation=activation))\n",
    "    \n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the kerastuner library\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs= 80,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 180 Complete [00h 01m 02s]\n",
      "val_accuracy: 0.7233819365501404\n",
      "\n",
      "Best val_accuracy So Far: 0.7240816354751587\n",
      "Total elapsed time: 00h 43m 38s\n"
     ]
    }
   ],
   "source": [
    "# Run the kerastuner search for best hyperparameters\n",
    "tuner.search(X_train_scaled,y_train,epochs=80,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'first_units': 11, 'num_layers': 5, 'units_0': 26, 'units_1': 21, 'units_2': 16, 'units_3': 21, 'units_4': 1, 'tuner/epochs': 80, 'tuner/initial_epoch': 27, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0078'}\n",
      "{'activation': 'tanh', 'first_units': 6, 'num_layers': 5, 'units_0': 6, 'units_1': 16, 'units_2': 6, 'units_3': 1, 'units_4': 21, 'tuner/epochs': 80, 'tuner/initial_epoch': 27, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0138'}\n",
      "{'activation': 'tanh', 'first_units': 16, 'num_layers': 5, 'units_0': 21, 'units_1': 1, 'units_2': 1, 'units_3': 21, 'units_4': 16, 'tuner/epochs': 80, 'tuner/initial_epoch': 27, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '0137'}\n"
     ]
    }
   ],
   "source": [
    "# Get top 3 model hyperparameters and print the values\n",
    "top_hyper = tuner.get_best_hyperparameters(3)\n",
    "for param in top_hyper:\n",
    "    print(param.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 1ms/step - accuracy: 0.7241 - loss: 0.5826\n",
      "Loss: 0.5825886130332947, Accuracy: 0.7240816354751587\n",
      "268/268 - 0s - 1ms/step - accuracy: 0.7241 - loss: 0.5822\n",
      "Loss: 0.5822045207023621, Accuracy: 0.7240816354751587\n",
      "268/268 - 0s - 1ms/step - accuracy: 0.7240 - loss: 0.5835\n",
      "Loss: 0.583514928817749, Accuracy: 0.7239649891853333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the top 3 models against the test dataset\n",
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'first_units': 6,\n",
       " 'num_layers': 5,\n",
       " 'units_0': 6,\n",
       " 'units_1': 16,\n",
       " 'units_2': 6,\n",
       " 'units_3': 1,\n",
       " 'units_4': 21,\n",
       " 'tuner/epochs': 80,\n",
       " 'tuner/initial_epoch': 27,\n",
       " 'tuner/bracket': 3,\n",
       " 'tuner/round': 3,\n",
       " 'tuner/trial_id': '0138'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get second best model hyperparameters\n",
    "second_hyper = tuner.get_best_hyperparameters(2)[1]\n",
    "second_hyper.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Used model tune up function to find top 3 models with best model hyperparameters. Used second best model hyperparameters for my final model. It sugests to use 5 layers and tanh activation function \n",
    "    instead of relu. For my final model increased number of epochs from 100 to 200. Also to reduce the noise in the system I used top 6 most important columns based on Decision Tree for feature importances evaluation instead of 43. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m42\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m102\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m7\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)             │            \u001b[38;5;34m42\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">327</span> (1.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m327\u001b[0m (1.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">327</span> (1.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m327\u001b[0m (1.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train.axes[1])\n",
    "hidden_nodes_layer1 =  6\n",
    "hidden_nodes_layer2 = 16\n",
    "hidden_nodes_layer3 =  6\n",
    "hidden_nodes_layer4 = 1\n",
    "hidden_nodes_layer5 =  21\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "\n",
    "# Forth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"tanh\"))\n",
    "\n",
    "# Fifth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"tanh\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25724, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(25724, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['ASK_AMT', 'AFFILIATION_CompanySponsored', 'APPLICATION_TYPE_T5',\n",
       "       'APPLICATION_TYPE_T10', 'ORGANIZATION_Association',\n",
       "       'APPLICATION_TYPE_T6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data size that goes into the model\n",
    "display(X_train_scaled.shape)\n",
    "display(y_train.shape)\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.6989 - loss: 0.6091\n",
      "Epoch 2/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - accuracy: 0.7185 - loss: 0.5904\n",
      "Epoch 3/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 0.7215 - loss: 0.5876\n",
      "Epoch 4/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7235 - loss: 0.5851\n",
      "Epoch 5/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7218 - loss: 0.5860\n",
      "Epoch 6/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.7165 - loss: 0.5912\n",
      "Epoch 7/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 0.7188 - loss: 0.5885\n",
      "Epoch 8/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.7231 - loss: 0.5835\n",
      "Epoch 9/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.7232 - loss: 0.5833\n",
      "Epoch 10/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.7202 - loss: 0.5867\n",
      "Epoch 11/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 0.7258 - loss: 0.5798\n",
      "Epoch 12/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.7257 - loss: 0.5812\n",
      "Epoch 13/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.7245 - loss: 0.5823\n",
      "Epoch 14/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.7192 - loss: 0.5867\n",
      "Epoch 15/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 0.7247 - loss: 0.5822\n",
      "Epoch 16/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7204 - loss: 0.5855\n",
      "Epoch 17/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 0.7216 - loss: 0.5855\n",
      "Epoch 18/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7243 - loss: 0.5794\n",
      "Epoch 19/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7235 - loss: 0.5828\n",
      "Epoch 20/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7249 - loss: 0.5809\n",
      "Epoch 21/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.7218 - loss: 0.5832\n",
      "Epoch 22/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7205 - loss: 0.5839\n",
      "Epoch 23/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.7215 - loss: 0.5828\n",
      "Epoch 24/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 0.7215 - loss: 0.5836\n",
      "Epoch 25/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.7245 - loss: 0.5815\n",
      "Epoch 26/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7235 - loss: 0.5804\n",
      "Epoch 27/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.7215 - loss: 0.5833\n",
      "Epoch 28/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 0.7228 - loss: 0.5811\n",
      "Epoch 29/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 0.7203 - loss: 0.5841\n",
      "Epoch 30/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.7221 - loss: 0.5826\n",
      "Epoch 31/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 0.7247 - loss: 0.5806\n",
      "Epoch 32/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 0.7187 - loss: 0.5878\n",
      "Epoch 33/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.7240 - loss: 0.5802\n",
      "Epoch 34/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.7258 - loss: 0.5785\n",
      "Epoch 35/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.7239 - loss: 0.5794\n",
      "Epoch 36/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 0.7254 - loss: 0.5788\n",
      "Epoch 37/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 0.7207 - loss: 0.5835\n",
      "Epoch 38/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.7216 - loss: 0.5829\n",
      "Epoch 39/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 0.7185 - loss: 0.5847\n",
      "Epoch 40/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 952us/step - accuracy: 0.7250 - loss: 0.5795\n",
      "Epoch 41/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 0.7231 - loss: 0.5813\n",
      "Epoch 42/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 0.7254 - loss: 0.5777\n",
      "Epoch 43/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.7197 - loss: 0.5854\n",
      "Epoch 44/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 0.7214 - loss: 0.5825\n",
      "Epoch 45/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 0.7232 - loss: 0.5812\n",
      "Epoch 46/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 952us/step - accuracy: 0.7239 - loss: 0.5800\n",
      "Epoch 47/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 0.7262 - loss: 0.5768\n",
      "Epoch 48/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7218 - loss: 0.5821\n",
      "Epoch 49/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.7256 - loss: 0.5802\n",
      "Epoch 50/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7234 - loss: 0.5813\n",
      "Epoch 51/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - accuracy: 0.7219 - loss: 0.5826\n",
      "Epoch 52/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - accuracy: 0.7291 - loss: 0.5760\n",
      "Epoch 53/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7253 - loss: 0.5797\n",
      "Epoch 54/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7199 - loss: 0.5818\n",
      "Epoch 55/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7212 - loss: 0.5832\n",
      "Epoch 56/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7182 - loss: 0.5836\n",
      "Epoch 57/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7239 - loss: 0.5808\n",
      "Epoch 58/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7171 - loss: 0.5852\n",
      "Epoch 59/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7176 - loss: 0.5852\n",
      "Epoch 60/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977us/step - accuracy: 0.7261 - loss: 0.5768\n",
      "Epoch 61/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955us/step - accuracy: 0.7222 - loss: 0.5822\n",
      "Epoch 62/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - accuracy: 0.7259 - loss: 0.5797\n",
      "Epoch 63/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7203 - loss: 0.5825\n",
      "Epoch 64/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7216 - loss: 0.5801\n",
      "Epoch 65/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - accuracy: 0.7230 - loss: 0.5806\n",
      "Epoch 66/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7259 - loss: 0.5796\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 0.7244 - loss: 0.5789\n",
      "Epoch 68/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.7222 - loss: 0.5828\n",
      "Epoch 69/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 0.7302 - loss: 0.5747\n",
      "Epoch 70/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7252 - loss: 0.5784\n",
      "Epoch 71/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 0.7254 - loss: 0.5794\n",
      "Epoch 72/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.7184 - loss: 0.5834\n",
      "Epoch 73/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.7233 - loss: 0.5770\n",
      "Epoch 74/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 0.7200 - loss: 0.5836\n",
      "Epoch 75/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.7254 - loss: 0.5805\n",
      "Epoch 76/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7197 - loss: 0.5824\n",
      "Epoch 77/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - accuracy: 0.7238 - loss: 0.5809\n",
      "Epoch 78/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.7243 - loss: 0.5792\n",
      "Epoch 79/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.7257 - loss: 0.5771\n",
      "Epoch 80/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 0.7234 - loss: 0.5794\n",
      "Epoch 81/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.7249 - loss: 0.5784\n",
      "Epoch 82/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.7238 - loss: 0.5801\n",
      "Epoch 83/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7216 - loss: 0.5810\n",
      "Epoch 84/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.7197 - loss: 0.5831\n",
      "Epoch 85/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - accuracy: 0.7211 - loss: 0.5824\n",
      "Epoch 86/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.7271 - loss: 0.5744\n",
      "Epoch 87/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.7189 - loss: 0.5832\n",
      "Epoch 88/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - accuracy: 0.7211 - loss: 0.5823\n",
      "Epoch 89/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.7284 - loss: 0.5768\n",
      "Epoch 90/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.7174 - loss: 0.5864\n",
      "Epoch 91/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.7207 - loss: 0.5812\n",
      "Epoch 92/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.7215 - loss: 0.5804\n",
      "Epoch 93/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.7222 - loss: 0.5811\n",
      "Epoch 94/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.7178 - loss: 0.5856\n",
      "Epoch 95/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 0.7227 - loss: 0.5802\n",
      "Epoch 96/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.7213 - loss: 0.5822\n",
      "Epoch 97/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7210 - loss: 0.5821\n",
      "Epoch 98/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7212 - loss: 0.5803\n",
      "Epoch 99/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 0.7177 - loss: 0.5861\n",
      "Epoch 100/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 0.7241 - loss: 0.5788\n",
      "Epoch 101/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 0.7213 - loss: 0.5834\n",
      "Epoch 102/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 0.7191 - loss: 0.5833\n",
      "Epoch 103/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.7297 - loss: 0.5734\n",
      "Epoch 104/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.7268 - loss: 0.5758\n",
      "Epoch 105/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - accuracy: 0.7232 - loss: 0.5796\n",
      "Epoch 106/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7239 - loss: 0.5788\n",
      "Epoch 107/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.7219 - loss: 0.5807\n",
      "Epoch 108/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 0.7238 - loss: 0.5802\n",
      "Epoch 109/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 0.7240 - loss: 0.5782\n",
      "Epoch 110/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 0.7208 - loss: 0.5819\n",
      "Epoch 111/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 0.7220 - loss: 0.5811\n",
      "Epoch 112/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 0.7202 - loss: 0.5841\n",
      "Epoch 113/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 0.7208 - loss: 0.5821\n",
      "Epoch 114/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 0.7220 - loss: 0.5827\n",
      "Epoch 115/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.7250 - loss: 0.5787\n",
      "Epoch 116/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.7183 - loss: 0.5846\n",
      "Epoch 117/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7229 - loss: 0.5814\n",
      "Epoch 118/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.7227 - loss: 0.5810\n",
      "Epoch 119/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.7234 - loss: 0.5781\n",
      "Epoch 120/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 0.7212 - loss: 0.5812\n",
      "Epoch 121/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 0.7280 - loss: 0.5747\n",
      "Epoch 122/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 0.7248 - loss: 0.5774\n",
      "Epoch 123/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.7274 - loss: 0.5773\n",
      "Epoch 124/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 0.7208 - loss: 0.5813\n",
      "Epoch 125/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.7234 - loss: 0.5794\n",
      "Epoch 126/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - accuracy: 0.7203 - loss: 0.5825\n",
      "Epoch 127/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.7246 - loss: 0.5798\n",
      "Epoch 128/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.7245 - loss: 0.5784\n",
      "Epoch 129/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 0.7208 - loss: 0.5803\n",
      "Epoch 130/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.7250 - loss: 0.5759\n",
      "Epoch 131/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 0.7252 - loss: 0.5781\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.7221 - loss: 0.5808\n",
      "Epoch 133/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.7216 - loss: 0.5817\n",
      "Epoch 134/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - accuracy: 0.7194 - loss: 0.5816\n",
      "Epoch 135/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 0.7203 - loss: 0.5831\n",
      "Epoch 136/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.7199 - loss: 0.5834\n",
      "Epoch 137/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.7287 - loss: 0.5739\n",
      "Epoch 138/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 0.7240 - loss: 0.5779\n",
      "Epoch 139/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.7215 - loss: 0.5803\n",
      "Epoch 140/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.7232 - loss: 0.5797\n",
      "Epoch 141/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.7227 - loss: 0.5792\n",
      "Epoch 142/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 0.7207 - loss: 0.5814\n",
      "Epoch 143/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.7247 - loss: 0.5782\n",
      "Epoch 144/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.7225 - loss: 0.5793\n",
      "Epoch 145/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.7247 - loss: 0.5785\n",
      "Epoch 146/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 0.7252 - loss: 0.5781\n",
      "Epoch 147/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.7177 - loss: 0.5848\n",
      "Epoch 148/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.7251 - loss: 0.5789\n",
      "Epoch 149/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - accuracy: 0.7200 - loss: 0.5846\n",
      "Epoch 150/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.7226 - loss: 0.5793\n",
      "Epoch 151/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.7187 - loss: 0.5848\n",
      "Epoch 152/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 0.7236 - loss: 0.5778\n",
      "Epoch 153/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.7260 - loss: 0.5769\n",
      "Epoch 154/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.7194 - loss: 0.5841\n",
      "Epoch 155/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7189 - loss: 0.5858\n",
      "Epoch 156/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - accuracy: 0.7220 - loss: 0.5823\n",
      "Epoch 157/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.7172 - loss: 0.5851\n",
      "Epoch 158/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.7194 - loss: 0.5843\n",
      "Epoch 159/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.7235 - loss: 0.5816\n",
      "Epoch 160/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.7223 - loss: 0.5799\n",
      "Epoch 161/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.7193 - loss: 0.5845\n",
      "Epoch 162/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 0.7232 - loss: 0.5778\n",
      "Epoch 163/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7253 - loss: 0.5783\n",
      "Epoch 164/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.7235 - loss: 0.5772\n",
      "Epoch 165/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 0.7245 - loss: 0.5796\n",
      "Epoch 166/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.7238 - loss: 0.5781\n",
      "Epoch 167/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 0.7224 - loss: 0.5802\n",
      "Epoch 168/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7249 - loss: 0.5782\n",
      "Epoch 169/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.7177 - loss: 0.5840\n",
      "Epoch 170/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7212 - loss: 0.5835\n",
      "Epoch 171/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.7188 - loss: 0.5833\n",
      "Epoch 172/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.7239 - loss: 0.5784\n",
      "Epoch 173/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.7259 - loss: 0.5735\n",
      "Epoch 174/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.7200 - loss: 0.5824\n",
      "Epoch 175/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - accuracy: 0.7188 - loss: 0.5832\n",
      "Epoch 176/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7240 - loss: 0.5782\n",
      "Epoch 177/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.7212 - loss: 0.5795\n",
      "Epoch 178/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 0.7272 - loss: 0.5741\n",
      "Epoch 179/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 0.7262 - loss: 0.5775\n",
      "Epoch 180/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7227 - loss: 0.5801\n",
      "Epoch 181/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7132 - loss: 0.5878\n",
      "Epoch 182/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7235 - loss: 0.5781\n",
      "Epoch 183/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.7230 - loss: 0.5797\n",
      "Epoch 184/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 0.7271 - loss: 0.5764\n",
      "Epoch 185/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 0.7237 - loss: 0.5795\n",
      "Epoch 186/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7259 - loss: 0.5777\n",
      "Epoch 187/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 0.7225 - loss: 0.5812\n",
      "Epoch 188/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.7219 - loss: 0.5818\n",
      "Epoch 189/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.7211 - loss: 0.5814\n",
      "Epoch 190/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.7165 - loss: 0.5867\n",
      "Epoch 191/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.7233 - loss: 0.5790\n",
      "Epoch 192/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.7212 - loss: 0.5815\n",
      "Epoch 193/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.7237 - loss: 0.5787\n",
      "Epoch 194/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 0.7215 - loss: 0.5810\n",
      "Epoch 195/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.7186 - loss: 0.5827\n",
      "Epoch 196/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.7241 - loss: 0.5799\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7238 - loss: 0.5784\n",
      "Epoch 198/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7207 - loss: 0.5796\n",
      "Epoch 199/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.7283 - loss: 0.5735\n",
      "Epoch 200/200\n",
      "\u001b[1m804/804\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.7230 - loss: 0.5793\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - 985us/step - accuracy: 0.7208 - loss: 0.5815\n",
      "Loss: 0.581484854221344, Accuracy: 0.7208163142204285\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity_Optimization.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
